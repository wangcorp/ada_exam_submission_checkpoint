{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exam - ada 2018  \n",
    "Schedule: _30.01.2019 / 08:15 - 11:15_\n",
    "\n",
    "**Student info:**  \n",
    "Name: Ruijia WANG  \n",
    "SCIPER: 223827  \n",
    "Faculty: SV\n",
    "\n",
    "### Important notes\n",
    "\n",
    "- To enhance your experience and your stay are, below are two suggested possible music to listen to while reviewing my code!\n",
    " * [Tarkus - Emerson, Lake & Palmer](https://www.youtube.com/watch?v=WKNOlDtZluU)\n",
    " * [Mahler: Symphony No. 1 \"The Titan\"](https://youtu.be/cQFjDBFXN58?t=44)\n",
    "- Have a nice day and good luck for the remaining copies to grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import folium\n",
    "import sklearn\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.helper_functions import *\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# (I used this on my computer to make spark work)\n",
    "import findspark\n",
    "findspark.init(r'C:\\Users\\Ruijia\\Spark') \n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Significant Bang Theory\n",
    "\n",
    "Attention, ADA students!\n",
    "\n",
    "The Sheldon Cooper we all know and love (OK, some of us might not know him, and some might not love him) from the TV series \"The Big Bang Theory\" has gotten into an argument with Leonard from the same TV show. Sheldon insists that he knows the show better than anyone, and keeps making various claims about the show, which neither of them know how to prove or disprove. The two of them have reached out to you ladies and gentlemen, as data scientists, to help them. You will be given the full script of the series, with information on the episode, the scene, the person saying each dialogue line, and the dialogue lines themselves.\n",
    "\n",
    "Leonard has challenged several of Sheldon's claims about the show, and throughout this exam you will see some of those and you will get to prove or disprove them, but remember: sometimes, we can neither prove a claim, nor disprove it!\n",
    "\n",
    "## Deadline\n",
    "Wednesday, January 30th, 2019; 11:15 A.M. (Swiss time)\n",
    "\n",
    "_For the deadline for extramural exams, see the submission subsection._\n",
    "\n",
    "## Important notes\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and your results!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code.\n",
    "* As we have seen during the semester, data science is all about multiple iterations on the same dataset. Do not obsess over small details in the beginning, and try to complete as many tasks as possible during the first 2 hours. Then, go back to the obtained results, write meaningful comments, and debug your code if you have found any glaring mistake.\n",
    "* Fully read the instructions for each question before starting to solve it to avoid misunderstandings, and remember to save your notebook often!\n",
    "* The exam contains **15 questions organised into 4 tasks**, and is designed for more than 3 hours. **You do not need to solve everything in order to get a 6**, and you have some freedom is choosing the tasks you wish to solve.\n",
    "* You cannot leave the room in the first and last 15 minutes.\n",
    "* You can use all the online resources you want except for communication tools (emails, web chats, forums, phone, etc.). We will be monitoring the network for unusual activity.\n",
    "* Remember, this is not a homework assignment -- no teamwork allowed!\n",
    "\n",
    "## Submission\n",
    "* Your file has to be named as \"NameSurname_SCIPER.ipynb\".\n",
    "* Make sure you upload your Jupyter Notebook (1 file) to [this](https://goo.gl/forms/7GLvYl94uSOn54jH2) Google form at the end of the exam, with all the cells already evaluated (except for the Spark-related question, Q7). You need to sign in to Google using your EPFL credentials in order to submit the form.\n",
    "* In case of problems with the form, send your Jupyter Notebook (along with your name and SCIPER number) as a direct message to @ramtin on Mattermost. This is reserved only for those who encounter problems with the submission -- you need to have a reasonable justification for using this back-up.\n",
    "* You will have until 11:20 (strict deadline) to turn in your submission. **Late submissions will not be accepted.** This deadline is for the students taking the exam at EPFL -- students taking the exam extramurally will have their submission deadline as the starting time of the exam plus 3 hours and 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task A: Picking up the shovel (10 points)\n",
    "\n",
    "**Note: You will use the data you preprocess in this task in all the subsequent ones.**\n",
    "\n",
    "Our friends' argument concerns the entire show. We have given you a file in the `data/` folder that contains the script of every single episode. New episodes are indicated by '>>', new scenes by '>', and the rest of the lines are dialogue lines. Some lines are said by multiple people (for example, lines indicated by 'All' or 'Together'); **you must discard these lines**, for the sake of simplicity. However, you do not need to do it for Q1 in this task -- you'll take care of it when you solve Q2.\n",
    "\n",
    "**Q1**. (5 points) Your first task is to extract all lines of dialogue in each scene and episode, creating a dataframe where each row has the episode and scene where a dialogue line was said, the character who said it, and the line itself. You do not need to extract the proper name of the episode (e.g. episode 1 can appear as \"Series 01 Episode 01 - Pilot Episode\", and doesn't need to appear as \"Pilot Episode\"). Then, answer the following question: In total, how many scenes are there in each season? We're not asking about unique scenes; the same location appearing in two episodes counts as two scenes. You can use a Pandas dataframe with a season column and a scene count column as the response.\n",
    "\n",
    "**Note: The data refers to seasons as \"series\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "HELPER_FOLDER = 'helper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data file\n",
    "f = open(DATA_FOLDER + '/all_scripts.txt', encoding=\"utf8\")\n",
    "\n",
    "content = f.readlines()\n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>episodes</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheldon: So if a photon is directed through a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard: Agreed, what’s your point?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sheldon: There’s no point, I just think it’s a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              series  episodes  lines\n",
       "0            >> Series 01 Episode 01 – Pilot Episode       NaN    NaN\n",
       "1                      > A corridor at a sperm bank.       NaN    NaN\n",
       "2  Sheldon: So if a photon is directed through a ...       NaN    NaN\n",
       "3                Leonard: Agreed, what’s your point?       NaN    NaN\n",
       "4  Sheldon: There’s no point, I just think it’s a...       NaN    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pd df\n",
    "all_scripts = pd.DataFrame(content)\n",
    "all_scripts.rename(columns={0: 'series'}, inplace=True)\n",
    "all_scripts['episodes']=np.nan\n",
    "all_scripts['lines']=np.nan\n",
    "all_scripts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54329, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the size of the file\n",
    "np.shape(all_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruijia\\Anaconda2\\envs\\ada\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Ruijia\\Anaconda2\\envs\\ada\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Ruijia\\Anaconda2\\envs\\ada\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Ruijia\\Anaconda2\\envs\\ada\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>episodes</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: So if a photon is directed through a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Agreed, what’s your point?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: There’s no point, I just think it’s a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Excuse me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: Hang on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: One across is Aegean, eight down is N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: Can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Yes. Um, is this the High IQ sperm bank?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: If you have to ask, maybe you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: I think this is the place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: Fill these out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Thank-you. We’ll be right back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: Oh, take your time. I’ll just fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: Leonard, I don’t think I can do this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: What, are you kidding? You’re a semi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: No. We are committing genetic fraud. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Sheldon, this was your idea. A little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: I know, and I do yearn for faster dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: I’m sure she’ll still love him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: I wouldn’t.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Well, what do you want to do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: I want to leave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: What’s the protocol for leaving?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: I don’t know, I’ve never reneged on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: Let’s try just walking out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Receptionist: Bye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54299</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; The street.</td>\n",
       "      <td>Sheldon: Bye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; The street.</td>\n",
       "      <td>Penny: We need to talk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54301</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; The street.</td>\n",
       "      <td>Sheldon: What? Is this about Leonard and Amy? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54302</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54303</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Okay, I know you don’t have a lot of ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54304</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: That doesn’t make any sense. She know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54305</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Well, sometimes women don’t care. Somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54306</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: That may be true, but Dr. Nowitzki’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54307</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Okay. Um, let’s try this. Think of your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54308</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: I already do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54309</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Well, then you get it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54310</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: Because there’s only one of me, I’m m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54311</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54312</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: Although, Amy’s already taken me out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54313</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Let’s forget the toy thing, okay? Um, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54314</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: Penny, look. I appreciate your concer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54315</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: All right. What do you think is happening?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54316</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Sheldon: I think Dr. Nowitzki is a friendly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54317</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon and Amy’s apartment.</td>\n",
       "      <td>Penny: Don’t look at me like that, I tried.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54318</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54319</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Ramona: Hey, did you eat yet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54320</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Sheldon: Uh, breakfast yes, lunch no. I did ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54321</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Ramona: Well, perfect. I made us sandwiches.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54322</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Sheldon: How thoughtful. Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54323</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Ramona: Mmm. No big deal, I enjoy spending tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54324</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Sheldon: And I with you. Question, are you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54325</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Ramona: What if I were?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54326</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Sheldon’s office.</td>\n",
       "      <td>Sheldon: Well, that would raise a number of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54327</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Princeton.</td>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54328</th>\n",
       "      <td>&gt;&gt; Series 10 Episode 24 – The Long Distance Di...</td>\n",
       "      <td>&gt; Princeton.</td>\n",
       "      <td>Sheldon: (Knock, knock, knock) Amy. (Knock, kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54329 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  series  \\\n",
       "0                >> Series 01 Episode 01 – Pilot Episode   \n",
       "1                >> Series 01 Episode 01 – Pilot Episode   \n",
       "2                >> Series 01 Episode 01 – Pilot Episode   \n",
       "3                >> Series 01 Episode 01 – Pilot Episode   \n",
       "4                >> Series 01 Episode 01 – Pilot Episode   \n",
       "5                >> Series 01 Episode 01 – Pilot Episode   \n",
       "6                >> Series 01 Episode 01 – Pilot Episode   \n",
       "7                >> Series 01 Episode 01 – Pilot Episode   \n",
       "8                >> Series 01 Episode 01 – Pilot Episode   \n",
       "9                >> Series 01 Episode 01 – Pilot Episode   \n",
       "10               >> Series 01 Episode 01 – Pilot Episode   \n",
       "11               >> Series 01 Episode 01 – Pilot Episode   \n",
       "12               >> Series 01 Episode 01 – Pilot Episode   \n",
       "13               >> Series 01 Episode 01 – Pilot Episode   \n",
       "14               >> Series 01 Episode 01 – Pilot Episode   \n",
       "15               >> Series 01 Episode 01 – Pilot Episode   \n",
       "16               >> Series 01 Episode 01 – Pilot Episode   \n",
       "17               >> Series 01 Episode 01 – Pilot Episode   \n",
       "18               >> Series 01 Episode 01 – Pilot Episode   \n",
       "19               >> Series 01 Episode 01 – Pilot Episode   \n",
       "20               >> Series 01 Episode 01 – Pilot Episode   \n",
       "21               >> Series 01 Episode 01 – Pilot Episode   \n",
       "22               >> Series 01 Episode 01 – Pilot Episode   \n",
       "23               >> Series 01 Episode 01 – Pilot Episode   \n",
       "24               >> Series 01 Episode 01 – Pilot Episode   \n",
       "25               >> Series 01 Episode 01 – Pilot Episode   \n",
       "26               >> Series 01 Episode 01 – Pilot Episode   \n",
       "27               >> Series 01 Episode 01 – Pilot Episode   \n",
       "28               >> Series 01 Episode 01 – Pilot Episode   \n",
       "29               >> Series 01 Episode 01 – Pilot Episode   \n",
       "...                                                  ...   \n",
       "54299  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54300  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54301  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54302  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54303  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54304  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54305  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54306  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54307  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54308  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54309  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54310  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54311  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54312  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54313  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54314  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54315  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54316  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54317  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54318  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54319  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54320  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54321  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54322  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54323  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54324  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54325  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54326  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54327  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "54328  >> Series 10 Episode 24 – The Long Distance Di...   \n",
       "\n",
       "                             episodes  \\\n",
       "0                                 NaN   \n",
       "1       > A corridor at a sperm bank.   \n",
       "2       > A corridor at a sperm bank.   \n",
       "3       > A corridor at a sperm bank.   \n",
       "4       > A corridor at a sperm bank.   \n",
       "5       > A corridor at a sperm bank.   \n",
       "6       > A corridor at a sperm bank.   \n",
       "7       > A corridor at a sperm bank.   \n",
       "8       > A corridor at a sperm bank.   \n",
       "9       > A corridor at a sperm bank.   \n",
       "10      > A corridor at a sperm bank.   \n",
       "11      > A corridor at a sperm bank.   \n",
       "12      > A corridor at a sperm bank.   \n",
       "13      > A corridor at a sperm bank.   \n",
       "14      > A corridor at a sperm bank.   \n",
       "15      > A corridor at a sperm bank.   \n",
       "16      > A corridor at a sperm bank.   \n",
       "17      > A corridor at a sperm bank.   \n",
       "18      > A corridor at a sperm bank.   \n",
       "19      > A corridor at a sperm bank.   \n",
       "20      > A corridor at a sperm bank.   \n",
       "21      > A corridor at a sperm bank.   \n",
       "22      > A corridor at a sperm bank.   \n",
       "23      > A corridor at a sperm bank.   \n",
       "24      > A corridor at a sperm bank.   \n",
       "25      > A corridor at a sperm bank.   \n",
       "26      > A corridor at a sperm bank.   \n",
       "27      > A corridor at a sperm bank.   \n",
       "28      > A corridor at a sperm bank.   \n",
       "29      > A corridor at a sperm bank.   \n",
       "...                               ...   \n",
       "54299                   > The street.   \n",
       "54300                   > The street.   \n",
       "54301                   > The street.   \n",
       "54302  > Sheldon and Amy’s apartment.   \n",
       "54303  > Sheldon and Amy’s apartment.   \n",
       "54304  > Sheldon and Amy’s apartment.   \n",
       "54305  > Sheldon and Amy’s apartment.   \n",
       "54306  > Sheldon and Amy’s apartment.   \n",
       "54307  > Sheldon and Amy’s apartment.   \n",
       "54308  > Sheldon and Amy’s apartment.   \n",
       "54309  > Sheldon and Amy’s apartment.   \n",
       "54310  > Sheldon and Amy’s apartment.   \n",
       "54311  > Sheldon and Amy’s apartment.   \n",
       "54312  > Sheldon and Amy’s apartment.   \n",
       "54313  > Sheldon and Amy’s apartment.   \n",
       "54314  > Sheldon and Amy’s apartment.   \n",
       "54315  > Sheldon and Amy’s apartment.   \n",
       "54316  > Sheldon and Amy’s apartment.   \n",
       "54317  > Sheldon and Amy’s apartment.   \n",
       "54318             > Sheldon’s office.   \n",
       "54319             > Sheldon’s office.   \n",
       "54320             > Sheldon’s office.   \n",
       "54321             > Sheldon’s office.   \n",
       "54322             > Sheldon’s office.   \n",
       "54323             > Sheldon’s office.   \n",
       "54324             > Sheldon’s office.   \n",
       "54325             > Sheldon’s office.   \n",
       "54326             > Sheldon’s office.   \n",
       "54327                    > Princeton.   \n",
       "54328                    > Princeton.   \n",
       "\n",
       "                                                   lines  \n",
       "0                                                    NaN  \n",
       "1                >> Series 01 Episode 01 – Pilot Episode  \n",
       "2      Sheldon: So if a photon is directed through a ...  \n",
       "3                    Leonard: Agreed, what’s your point?  \n",
       "4      Sheldon: There’s no point, I just think it’s a...  \n",
       "5                                    Leonard: Excuse me?  \n",
       "6                                 Receptionist: Hang on.  \n",
       "7      Leonard: One across is Aegean, eight down is N...  \n",
       "8                          Receptionist: Can I help you?  \n",
       "9      Leonard: Yes. Um, is this the High IQ sperm bank?  \n",
       "10     Receptionist: If you have to ask, maybe you sh...  \n",
       "11                   Sheldon: I think this is the place.  \n",
       "12                         Receptionist: Fill these out.  \n",
       "13              Leonard: Thank-you. We’ll be right back.  \n",
       "14     Receptionist: Oh, take your time. I’ll just fi...  \n",
       "15        Sheldon: Leonard, I don’t think I can do this.  \n",
       "16     Leonard: What, are you kidding? You’re a semi-...  \n",
       "17     Sheldon: No. We are committing genetic fraud. ...  \n",
       "18     Leonard: Sheldon, this was your idea. A little...  \n",
       "19     Sheldon: I know, and I do yearn for faster dow...  \n",
       "20              Leonard: I’m sure she’ll still love him.  \n",
       "21                                  Sheldon: I wouldn’t.  \n",
       "22                Leonard: Well, what do you want to do?  \n",
       "23                             Sheldon: I want to leave.  \n",
       "24                                        Leonard: Okay.  \n",
       "25             Sheldon: What’s the protocol for leaving?  \n",
       "26     Leonard: I don’t know, I’ve never reneged on a...  \n",
       "27                  Sheldon: Let’s try just walking out.  \n",
       "28                                        Leonard: Okay.  \n",
       "29                                    Receptionist: Bye.  \n",
       "...                                                  ...  \n",
       "54299                                      Sheldon: Bye.  \n",
       "54300                            Penny: We need to talk.  \n",
       "54301  Sheldon: What? Is this about Leonard and Amy? ...  \n",
       "54302  >> Series 10 Episode 24 – The Long Distance Di...  \n",
       "54303  Penny: Okay, I know you don’t have a lot of ex...  \n",
       "54304  Sheldon: That doesn’t make any sense. She know...  \n",
       "54305  Penny: Well, sometimes women don’t care. Somet...  \n",
       "54306  Sheldon: That may be true, but Dr. Nowitzki’s ...  \n",
       "54307  Penny: Okay. Um, let’s try this. Think of your...  \n",
       "54308                             Sheldon: I already do.  \n",
       "54309                      Penny: Well, then you get it.  \n",
       "54310  Sheldon: Because there’s only one of me, I’m m...  \n",
       "54311                                      Penny: Right.  \n",
       "54312  Sheldon: Although, Amy’s already taken me out ...  \n",
       "54313  Penny: Let’s forget the toy thing, okay? Um, m...  \n",
       "54314  Sheldon: Penny, look. I appreciate your concer...  \n",
       "54315  Penny: All right. What do you think is happening?  \n",
       "54316  Sheldon: I think Dr. Nowitzki is a friendly co...  \n",
       "54317        Penny: Don’t look at me like that, I tried.  \n",
       "54318  >> Series 10 Episode 24 – The Long Distance Di...  \n",
       "54319                      Ramona: Hey, did you eat yet?  \n",
       "54320  Sheldon: Uh, breakfast yes, lunch no. I did ha...  \n",
       "54321       Ramona: Well, perfect. I made us sandwiches.  \n",
       "54322                Sheldon: How thoughtful. Thank you.  \n",
       "54323  Ramona: Mmm. No big deal, I enjoy spending tim...  \n",
       "54324  Sheldon: And I with you. Question, are you see...  \n",
       "54325                            Ramona: What if I were?  \n",
       "54326  Sheldon: Well, that would raise a number of pr...  \n",
       "54327  >> Series 10 Episode 24 – The Long Distance Di...  \n",
       "54328  Sheldon: (Knock, knock, knock) Amy. (Knock, kn...  \n",
       "\n",
       "[54329 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now separate each >> and > and '' as new columns\n",
    "for i in range(len(all_scripts)):\n",
    "    if \">>\" in all_scripts['series'][i]:\n",
    "        current_series = all_scripts['series'][i]\n",
    "    if \">>\" not in all_scripts['series'][i]:\n",
    "        if \">\" in all_scripts['series'][i]:\n",
    "            current_episodes = all_scripts['series'][i]\n",
    "            all_scripts['episodes'][i] = all_scripts['series'][i]\n",
    "            all_scripts['series'][i] = current_series\n",
    "        if \">\" not in all_scripts['series']:\n",
    "            all_scripts['lines'][i] = all_scripts['series'][i]\n",
    "            all_scripts['episodes'][i] = current_episodes\n",
    "            all_scripts['series'][i] = current_series\n",
    "            \n",
    "all_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>> Series 01 Episode 01 – Pilot\\xa0Episode',\n",
       "       '>> Series 01 Episode 02 – The Big Bran\\xa0Hypothesis',\n",
       "       '>> Series 01 Episode 03 – The Fuzzy Boots\\xa0Corollary',\n",
       "       '>> Series 01 Episode 04 – The Luminous Fish\\xa0Effect',\n",
       "       '>> Series 01 Episode 05 – The Hamburger\\xa0Postulate',\n",
       "       '>> Series 01 Episode 06 – The Middle Earth\\xa0Paradigm',\n",
       "       '>> Series 01 Episode 07 – The Dumpling\\xa0Paradox',\n",
       "       '>> Series 01 Episode 08 – The Grasshopper\\xa0Experiment',\n",
       "       '>> Series 01 Episode 09 – The Cooper-Hofstadter Polarization',\n",
       "       '>> Series 01 Episode 10 – The Loobenfeld\\xa0Decay',\n",
       "       '>> Series 01 Episode 11 – The Pancake Batter\\xa0Anomaly',\n",
       "       '>> Series 01 Episode 12 – The Jerusalem\\xa0Duality',\n",
       "       '>> Series 01 Episode 13 – The Bat Jar\\xa0Conjecture',\n",
       "       '>> Series 01 Episode 14 – The Nerdvana\\xa0Annihilation',\n",
       "       '>> Series 01 Episode 15 – The Porkchop\\xa0Indeterminacy',\n",
       "       '>> Series 01 Episode 16 – The Peanut\\xa0Reaction',\n",
       "       '>> Series 01 Episode 17 – The Tangerine\\xa0Factor',\n",
       "       '>> Series 02 Episode 01 – The Bad Fish\\xa0Paradigm',\n",
       "       '>> Series 02 Episode 02 – The Codpiece\\xa0Topology',\n",
       "       '>> Series 02 Episode 03 – The Barbarian\\xa0Sublimation',\n",
       "       '>> Series 02 Episode 04 – The Griffin\\xa0Equivalency',\n",
       "       '>> Series 02 Episode 05 – The Euclid\\xa0Alternative',\n",
       "       '>> Series 02 Episode 06 – The Cooper-Nowitzki\\xa0Theorem',\n",
       "       '>> Series 02 Episode 07 – The Panty Pinata\\xa0Polarization',\n",
       "       '>> Series 02 Episode 08 – The Lizard-Spock\\xa0Expansion',\n",
       "       '>> Series 02 Episode 09 – The White Asparagus\\xa0Triangulation',\n",
       "       '>> Series 02 Episode 10 – The Vartabedian\\xa0Conundrum',\n",
       "       '>> Series 02 Episode 11 – The Bath Item Gift\\xa0Hypothesis',\n",
       "       '>> Series 02 Episode 12 – The Killer Robot\\xa0Instability',\n",
       "       '>> Series 02 Episode 13 – The Friendship\\xa0Algorithm',\n",
       "       '>> Series 02 Episode 14 – The Financial\\xa0Permeability',\n",
       "       '>> Series 02 Episode 15 – The Maternal\\xa0Capacitance',\n",
       "       '>> Series 02 Episode 16 – The Cushion\\xa0Saturation',\n",
       "       '>> Series 02 Episode 17 – The Terminator\\xa0Decoupling',\n",
       "       '>> Series 02 Episode 18 – The Work Song\\xa0Nanocluster',\n",
       "       '>> Series 02 Episode 19 – The Dead Hooker\\xa0Juxtaposition',\n",
       "       '>> Series 02 Episode 20 – The Hofstadter\\xa0Isotope',\n",
       "       '>> Series 02 Episode 21 – The Vegas\\xa0Renormalization',\n",
       "       '>> Series 02 Episode 22 – The Classified Materials\\xa0Turbulence',\n",
       "       '>> Series 02 Episode 23 – The Monopolar\\xa0Expedition',\n",
       "       '>> Series 03 Episode 01 – The Electric Can Opener\\xa0Fluctuation',\n",
       "       '>> Series 03 Episode 02 – The Jiminy\\xa0Conjecture',\n",
       "       '>> Series 03 Episode 03 – The Gothowitz\\xa0Deviation',\n",
       "       '>> Series 03 Episode 04 – The Pirate\\xa0Solution',\n",
       "       '>> Series 03 Episode 05 – The Creepy Candy Coating\\xa0Corollary',\n",
       "       '>> Series 03 Episode 06 – The Cornhusker\\xa0Vortex',\n",
       "       '>> Series 03 Episode 07 – The Guitarist\\xa0Amplification',\n",
       "       '>> Series 03 Episode 08 – The Adhesive Duck\\xa0Deficiency',\n",
       "       '>> Series 03 Episode 09 – The Vengeance\\xa0Formulation',\n",
       "       '>> Series 03 Episode 10 – The Gorilla\\xa0Experiment',\n",
       "       '>> Series 03 Episode 11 – The Maternal\\xa0Congruence',\n",
       "       '>> Series 03 Episode 12 – The Psychic\\xa0Vortex',\n",
       "       '>> Series 03 Episode 13 – The Bozeman\\xa0Reaction',\n",
       "       '>> Series 03 Episode 14 – The Einstein\\xa0Approximation',\n",
       "       '>> Series 03 Episode 15 – The Large Hadron\\xa0Collision',\n",
       "       '>> Series 03 Episode 16 – The Excelsior\\xa0Acquisition',\n",
       "       '>> Series 03 Episode 17 – The Precious\\xa0Fragmentation',\n",
       "       '>> Series 03 Episode 18 – The Pants\\xa0Alternative',\n",
       "       '>> Series 03 Episode 19 – The Wheaton\\xa0Recurrence',\n",
       "       '>> Series 03 Episode 20 – The Spaghetti\\xa0Catalyst',\n",
       "       '>> Series 03 Episode 21 – The Plimpton\\xa0Stimulation',\n",
       "       '>> Series 03 Episode 22 – The Staircase\\xa0Implementation',\n",
       "       '>> Series 03 Episode 23 – The Lunar\\xa0Excitation',\n",
       "       '>> Series 04 Episode 01 – The Robotic\\xa0Manipulation',\n",
       "       '>> Series 04 Episode 02 – The Cruciferous Vegetable\\xa0Amplification',\n",
       "       '>> Series 04 Episode 03 – The Zazzy\\xa0Substitution',\n",
       "       '>> Series 04 Episode 04 – The Hot Troll\\xa0Deviation',\n",
       "       '>> Series 04 Episode 05 – The Desperation\\xa0Emanation',\n",
       "       '>> Series 04 Episode 06 – The Irish Pub\\xa0Formulation',\n",
       "       '>> Series 04 Episode 07 – The Apology\\xa0Insufficiency',\n",
       "       '>> Series 04 Episode 08 – The 21 Second\\xa0Excitation',\n",
       "       '>> Series 04 Episode 09 – The Boyfriend\\xa0Complexity',\n",
       "       '>> Series 04 Episode 10 – The Alien Parasite\\xa0Hypothesis',\n",
       "       '>> Series 04 Episode 11 – The Justice League\\xa0Recombination',\n",
       "       '>> Series 04 Episode 12 – The Bus Pants\\xa0Utilization',\n",
       "       '>> Series 04 Episode 13 – The Love Car\\xa0Displacement',\n",
       "       '>> Series 04 Episode 14 – The Thespian\\xa0Catalyst',\n",
       "       '>> Series 04 Episode 15 – The Benefactor\\xa0Factor',\n",
       "       '>> Series 04 Episode 16 – The Cohabitation\\xa0Formulation',\n",
       "       '>> Series 04 Episode 17 – The Toast\\xa0Derivation',\n",
       "       '>> Series 04 Episode 18 – The Prestidigitation Approximation',\n",
       "       '>> Series 04 Episode 19 – The Zarnecki\\xa0Incursion',\n",
       "       '>> Series 04 Episode 20 – The Herb Garden\\xa0Germination',\n",
       "       '>> Series 04 Episode 21 – The Agreement\\xa0Dissection',\n",
       "       '>> Series 04 Episode 22 – The Wildebeest\\xa0Implementation',\n",
       "       '>> Series 04 Episode 23 – The Engagement\\xa0Reaction',\n",
       "       '>> Series 04 Episode 24 – The Roommate Transmogrification',\n",
       "       '>> Series 05 Episode 01 – The Skank Reflex\\xa0Analysis',\n",
       "       '>> Series 05 Episode 02 – The Infestation\\xa0Hypothesis',\n",
       "       '>> Series 05 Episode 03 – The Pulled Groin\\xa0Extrapolation',\n",
       "       '>> Series 05 Episode 04 – The Wiggly Finger\\xa0Catalyst',\n",
       "       '>> Series 05 Episode 05 – The Russian Rocket\\xa0Reaction',\n",
       "       '>> Series 05 Episode 06 – The Rhinitis\\xa0Revelation',\n",
       "       '>> Series 05 Episode 07 – The Good Guy\\xa0Fluctuation',\n",
       "       '>> Series 05 Episode 08 – The Isolation\\xa0Permutation',\n",
       "       '>> Series 05 Episode 09 – The Ornithophobia\\xa0Diffusion',\n",
       "       '>> Series 05 Episode 10 – The Flaming Spittoon\\xa0Acquisition',\n",
       "       '>> Series 05 Episode 11 – The Speckerman\\xa0Recurrence',\n",
       "       '>> Series 05 Episode 12 – The Shiny Trinket\\xa0Maneouvre',\n",
       "       '>> Series 05 Episode 13 – The Recombination\\xa0Hypothesis',\n",
       "       '>> Series 05 Episode 14 – The Beta Test\\xa0Initiation',\n",
       "       '>> Series 05 Episode 15 – The Friendship\\xa0Contraction',\n",
       "       '>> Series 05 Episode 16 – The Vacation\\xa0Solution',\n",
       "       '>> Series 05 Episode 17 – The Rothman\\xa0Disintegration',\n",
       "       '>> Series 05 Episode 18 – The Werewolf\\xa0Transformation',\n",
       "       '>> Series 05 Episode 19 – The Weekend\\xa0Vortex',\n",
       "       '>> Series 05 Episode 20 – The Transporter\\xa0Malfunction',\n",
       "       '>> Series 05 Episode 21 – The Hawking\\xa0Excitation',\n",
       "       '>> Series 05 Episode 22 – The Stag\\xa0Convergence',\n",
       "       '>> Series 05 Episode 23 – The Launch\\xa0Acceleration',\n",
       "       '>> Series 05 Episode 24 – The Countdown\\xa0Reflection',\n",
       "       '>> Series 06 Episode 01 – The Date Night\\xa0Variable',\n",
       "       '>> Series 06 Episode 02 – The Decoupling\\xa0Fluctuation',\n",
       "       '>> Series 06 Episode 03 – The Higgs Boson\\xa0Observation',\n",
       "       '>> Series 06 Episode 04 – The Re-Entry\\xa0Minimization',\n",
       "       '>> Series 06 Episode 05 – The Holographic\\xa0Excitation',\n",
       "       '>> Series 06 Episode 06 – The Extract\\xa0Obliteration',\n",
       "       '>> Series 06 Episode 07 – The Habitation\\xa0Configuration',\n",
       "       '>> Series 06 Episode 08 – The 43\\xa0Peculiarity',\n",
       "       '>> Series 06 Episode 09 – The Parking Spot\\xa0Escalation',\n",
       "       '>> Series 06 Episode 10 – The Fish Guts\\xa0Displacement',\n",
       "       '>> Series 06 Episode 11 – The Santa\\xa0Simulation',\n",
       "       '>> Series 06 Episode 12 – The Egg Salad\\xa0Equivalency',\n",
       "       '>> Series 06 Episode 13 – The Bakersfield\\xa0Expedition',\n",
       "       '>> Series 06 Episode 14 – The Cooper/Kripke\\xa0Inversion',\n",
       "       '>> Series 06 Episode 15 – The Spoiler Alert\\xa0Segmentation',\n",
       "       '>> Series 06 Episode 16 – The Tangible Affection\\xa0Proof',\n",
       "       '>> Series 06 Episode 17 – The Monster\\xa0Isolation',\n",
       "       '>> Series 06 Episode 18 – The Contractual Obligation\\xa0Implementation',\n",
       "       '>> Series 06 Episode 19 – The Closet\\xa0Reconfiguration',\n",
       "       '>> Series 06 Episode 20 – The Tenure\\xa0Turbulence',\n",
       "       '>> Series 06 Episode 21 – The Closure\\xa0Alternative',\n",
       "       '>> Series 06 Episode 22 – The Proton\\xa0Resurgence',\n",
       "       '>> Series 06 Episode 23 – The Love Spell\\xa0Potential',\n",
       "       '>> Series 06 Episode 24 – The Bon Voyage\\xa0Reaction',\n",
       "       '>> Series 07 Episode 01 – The Hofstadter\\xa0Insufficiency',\n",
       "       '>> Series 07 Episode 02 – The Deception\\xa0Verification',\n",
       "       '>> Series 07 Episode 03 – The Scavenger\\xa0Vortex',\n",
       "       '>> Series 07 Episode 04 – The Raiders\\xa0Minimization',\n",
       "       '>> Series 07 Episode 05 – The Workplace\\xa0Proximity',\n",
       "       '>> Series 07 Episode 06 – The Romance\\xa0Resonance',\n",
       "       '>> Series 07 Episode 07 – The Proton\\xa0Displacement',\n",
       "       '>> Series 07 Episode 08 – The Itchy Brain\\xa0Simulation',\n",
       "       '>> Series 07 Episode 09 – The Thanksgiving\\xa0Decoupling',\n",
       "       '>> Series 07 Episode 10 – The Discovery\\xa0Dissipation',\n",
       "       '>> Series 07 Episode 11 – The Cooper\\xa0Extraction',\n",
       "       '>> Series 07 Episode 12 – The Hesitation\\xa0Ramification',\n",
       "       '>> Series 07 Episode 13 – The Occupation\\xa0Recalibration',\n",
       "       '>> Series 07 Episode 14 – The Convention\\xa0Conundrum',\n",
       "       '>> Series 07 Episode 15 – The Locomotive\\xa0Manipulation',\n",
       "       '>> Series 07 Episode 16 – The Table\\xa0Polarisation',\n",
       "       '>> Series 07 Episode 17 – The Friendship\\xa0Turbulence',\n",
       "       '>> Series 07 Episode 18 – The Mommy\\xa0Observation',\n",
       "       '>> Series 07 Episode 19 – The Indecision\\xa0Amalgamation',\n",
       "       '>> Series 07 Episode 20 – The Relationship\\xa0Diremption',\n",
       "       '>> Series 07 Episode 21 – The Anything Can Happen\\xa0Recurrence',\n",
       "       '>> Series 07 Episode 22 – The Proton Transmogrification',\n",
       "       '>> Series 07 Episode 23 – The Gorilla\\xa0Dissolution',\n",
       "       '>> Series 07 Episode 24 – The Status Quo\\xa0Combustion',\n",
       "       '>> Series 08 Episode 01 – The Locomotion\\xa0Interruption',\n",
       "       '>> Series 08 Episode 02 – The Junior Professor\\xa0Solution',\n",
       "       '>> Series 08 Episode 03 – The First Pitch\\xa0Insufficiency',\n",
       "       '>> Series 08 Episode 04 – The Hook-Up\\xa0Reverbration',\n",
       "       '>> Series 08 Episode 05 – The Focus\\xa0Attenuation',\n",
       "       '>> Series 08 Episode 06 – The Expedition\\xa0Approximation',\n",
       "       '>> Series 08 Episode 07 – The Misinterpretation Agitation',\n",
       "       '>> Series 08 Episode 08 – The Prom\\xa0Equivalency',\n",
       "       '>> Series 08 Episode 09 – The Septum\\xa0Deviation',\n",
       "       '>> Series 08 Episode 10 – The Champagne\\xa0Reflection',\n",
       "       '>> Series 08 Episode 11 – The Clean Room\\xa0Infiltration',\n",
       "       '>> Series 08 Episode 12 – The Space Probe\\xa0Disintegration',\n",
       "       '>> Series 08 Episode 13 – The Anxiety\\xa0Optimisation',\n",
       "       '>> Series 08 Episode 14 – The Troll\\xa0Manifestation',\n",
       "       '>> Series 08 Episode 15 – The Comic Book Store\\xa0Regeneration',\n",
       "       '>> Series 08 Episode 16 – The Intimacy\\xa0Acceleration',\n",
       "       '>> Series 08 Episode 17 – The Colonization\\xa0Application',\n",
       "       '>> Series 08 Episode 18 – The Leftover\\xa0Thermalization',\n",
       "       '>> Series 08 Episode 19 – The Skywalker\\xa0Incursion',\n",
       "       '>> Series 08 Episode 20 – The Fortification\\xa0Implementation',\n",
       "       '>> Series 08 Episode 21 – The Communication\\xa0Deterioration',\n",
       "       '>> Series 08 Episode 22 – The Graduation\\xa0Transmission',\n",
       "       '>> Series 08 Episode 23 – The Maternal\\xa0Combustion',\n",
       "       '>> Series 08 Episode 24 – The Commitment\\xa0Determination',\n",
       "       '>> Series 09 Episode 01 – The Matrimonial\\xa0Momentum',\n",
       "       '>> Series 09 Episode 02 – The Separation\\xa0Oscillation',\n",
       "       '>> Series 09 Episode 03 – The Batchelor Party\\xa0Corrosion',\n",
       "       '>> Series 09 Episode 04 – The 2003\\xa0Approximation',\n",
       "       '>> Series 09 Episode 05 – The Perspiration\\xa0Implementation',\n",
       "       '>> Series 09 Episode 06 – The Helium\\xa0Insufficiency',\n",
       "       '>> Series 09 Episode 07 – The Spock\\xa0Resonance',\n",
       "       '>> Series 09 Episode 08 – The Mystery Date\\xa0Observation',\n",
       "       '>> Series 09 Episode 09 – The Platonic\\xa0Permutation',\n",
       "       '>> Series 09 Episode 10 – The Earworm\\xa0Reverberation',\n",
       "       '>> Series 09 Episode 11 – The Opening Night\\xa0Excitation',\n",
       "       '>> Series 09 Episode 12 – The Sales Call\\xa0Sublimation',\n",
       "       '>> Series 09 Episode 13 – The Empathy\\xa0Optimisation',\n",
       "       '>> Series 09 Episode 14 – The Meemaw\\xa0Materialisation',\n",
       "       '>> Series 09 Episode 15 – The Valentino\\xa0Submergence',\n",
       "       '>> Series 09 Episode 16 – The Positive Negative\\xa0Reaction',\n",
       "       '>> Series 09 Episode 17 – The Celebration\\xa0Experimentation',\n",
       "       '>> Series 09 Episode 18 – The Application\\xa0Deterioration',\n",
       "       '>> Series 09 Episode 19 – The Solder Excursion\\xa0Diversion',\n",
       "       '>> Series 09 Episode 20 – The Big Bear\\xa0Precipitation',\n",
       "       '>> Series 09 Episode 21 – The Viewing Party\\xa0Combustion',\n",
       "       '>> Series 09 Episode 22 – The Fermentation\\xa0Bifurcation',\n",
       "       '>> Series 09 Episode 23 – The Line Substitution\\xa0Solution',\n",
       "       '>> Series 09 Episode 24 – The Convergence\\xa0Convergence',\n",
       "       '>> Series 10 Episode 01 – The Conjugal\\xa0Conjecture',\n",
       "       '>> Series 10 Episode 02 – The Military\\xa0Miniturization',\n",
       "       '>> Series 10 Episode 03 – The Dependence\\xa0Transcendence',\n",
       "       '>> Series 10 Episode 04 – The Cohabitation\\xa0Experimentation',\n",
       "       '>> Series 10 Episode 05 – The Hot Tub\\xa0Contamination',\n",
       "       '>> Series 10 Episode 06 – The Foetal Kick\\xa0Catalyst',\n",
       "       '>> Series 10 Episode 07 – The Veracity\\xa0Elasticity',\n",
       "       '>> Series 10 Episode 08 – The Brain Bowl\\xa0Incubation',\n",
       "       '>> Series 10 Episode 09 – The Geology\\xa0Elevation',\n",
       "       '>> Series 10 Episode 10 – The Property Division\\xa0Collision',\n",
       "       '>> Series 10 Episode 11 – The Birthday\\xa0Synchronicity',\n",
       "       '>> Series 10 Episode 12 – The Holiday\\xa0Summation',\n",
       "       '>> Series 10 Episode 13 – The Romance\\xa0Recalibration',\n",
       "       '>> Series 10 Episode 14 – The Emotion Detection\\xa0Automation',\n",
       "       '>> Series 10 Episode 15 – The Locomotion\\xa0Reverberation',\n",
       "       '>> Series 10 Episode 16 – The Allowance\\xa0Evaporation',\n",
       "       '>> Series 10 Episode 17 – The Comic-Con\\xa0Conundrum',\n",
       "       '>> Series 10 Episode 18 – The Escape Hatch\\xa0Identification',\n",
       "       '>> Series 10 Episode 19 – The Collaboration\\xa0Fluctuation',\n",
       "       '>> Series 10 Episode 20 – The Recollection\\xa0Dissipation',\n",
       "       '>> Series 10 Episode 21 – The Separation\\xa0Agitation',\n",
       "       '>> Series 10 Episode 22 – The Cognition\\xa0Regeneration',\n",
       "       '>> Series 10 Episode 23 – The Gyroscopic\\xa0Collapse',\n",
       "       '>> Series 10 Episode 24 – The Long Distance\\xa0Dissonance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of series\n",
    "all_scripts['series'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In season 1, there is around:  4313 lines.\n",
      "In season 2, there is around:  5492 lines.\n",
      "In season 3, there is around:  5289 lines.\n",
      "In season 4, there is around:  5907 lines.\n",
      "In season 5, there is around:  5125 lines.\n",
      "In season 6, there is around:  5213 lines.\n",
      "In season 7, there is around:  5701 lines.\n",
      "In season 8, there is around:  5620 lines.\n",
      "In season 9, there is around:  5779 lines.\n",
      "In season 10, there is around:  5890 lines.\n"
     ]
    }
   ],
   "source": [
    "# There are 10 series\n",
    "def mask_series(df, str):\n",
    "    s = pd.Series(df['series'])\n",
    "    return s.str.startswith('>> Series '+ str)\n",
    "\n",
    "mask1 = mask_series(all_scripts, '01')\n",
    "print('In season 1, there is around: ', len(all_scripts[mask1]), 'lines.')\n",
    "\n",
    "mask2 = mask_series(all_scripts, '02')\n",
    "print('In season 2, there is around: ', len(all_scripts[mask2]), 'lines.')\n",
    "\n",
    "mask3 = mask_series(all_scripts, '03')\n",
    "print('In season 3, there is around: ', len(all_scripts[mask3]), 'lines.')\n",
    "\n",
    "mask4 = mask_series(all_scripts, '04')\n",
    "print('In season 4, there is around: ', len(all_scripts[mask4]), 'lines.')\n",
    "\n",
    "mask5 = mask_series(all_scripts, '05')\n",
    "print('In season 5, there is around: ', len(all_scripts[mask5]), 'lines.')\n",
    "\n",
    "mask6 = mask_series(all_scripts, '06')\n",
    "print('In season 6, there is around: ', len(all_scripts[mask6]), 'lines.')\n",
    "\n",
    "mask7 = mask_series(all_scripts, '07')\n",
    "print('In season 7, there is around: ', len(all_scripts[mask7]), 'lines.')\n",
    "\n",
    "mask8 = mask_series(all_scripts, '08')\n",
    "print('In season 8, there is around: ', len(all_scripts[mask8]), 'lines.')\n",
    "\n",
    "mask9 = mask_series(all_scripts, '09')\n",
    "print('In season 9, there is around: ', len(all_scripts[mask9]), 'lines.')\n",
    "\n",
    "mask10 = mask_series(all_scripts, '10')\n",
    "print('In season 10, there is around: ', len(all_scripts[mask10]), 'lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. (5 points) Now, let's define two sets of characters: all the characters, and recurrent characters. Recurrent characters are those who appear in more than one episode. For the subsequent sections, you will need to have a list of recurrent characters. Assume that there are no two _named characters_ (i.e. characters who have actual names and aren't referred to generically as \"little girl\", \"grumpy grandpa\", etc.) with the same name, i.e. there are no two Sheldons, etc. Generate a list of recurrent characters who have more than 90 dialogue lines in total, and then take a look at the list you have. If you've done this correctly, you should have a list of 20 names. However, one of these is clearly not a recurrent character. Manually remove that one, and print out your list of recurrent characters. To remove that character, pay attention to the _named character_ assumption we gave you earlier on. **For all the subsequent questions, you must only keep the dialogue lines said by the recurrent characters in your list.**\n",
    "\n",
    "_Hint: \"I know all the recurrent characters because I've watched the entire series five times\" is not an acceptable argument, so you need to actually generate the list._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>name_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Amy</td>\n",
       "      <td>3471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Arthur</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Bernadette</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Bert</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Beverley</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Emily</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Howard</td>\n",
       "      <td>5872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Kripke</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Leonard</td>\n",
       "      <td>9829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Leslie</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Man</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Mrs Cooper</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Mrs Wolowitz</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Penny</td>\n",
       "      <td>7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Priya</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Raj</td>\n",
       "      <td>4779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Sheldon</td>\n",
       "      <td>11687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Stuart</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Wil</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Zack</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            names  name_count\n",
       "241           Amy        3471\n",
       "244        Arthur         130\n",
       "251    Bernadette        2689\n",
       "252          Bert          95\n",
       "254      Beverley         162\n",
       "283         Emily         164\n",
       "302        Howard        5872\n",
       "321        Kripke         106\n",
       "326       Leonard        9829\n",
       "329        Leslie         116\n",
       "332           Man         105\n",
       "352    Mrs Cooper         213\n",
       "359  Mrs Wolowitz         136\n",
       "368         Penny        7677\n",
       "373         Priya         222\n",
       "378           Raj        4779\n",
       "391       Sheldon       11687\n",
       "404        Stuart         733\n",
       "422           Wil         126\n",
       "427          Zack         135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split at character name\n",
    "temp = all_scripts.lines.str.split(':', expand=True)\n",
    "temp.rename(columns={0: 'names', 1: 'lines' }, inplace=True)\n",
    "\n",
    "name_line = temp[['names','lines']]\n",
    "\n",
    "all_scripts['names'] = name_line['names']\n",
    "\n",
    "# Count the appearing names\n",
    "name_count = all_scripts\n",
    "name_count['name_count'] = 0.0\n",
    "name_count = name_count.groupby(['names']).count().reset_index()\n",
    "\n",
    "# Display name with more than 90 appearance\n",
    "name_count = name_count[name_count['name_count'] > 90]\n",
    "name_count[['names', 'name_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>episodes</th>\n",
       "      <th>lines</th>\n",
       "      <th>names</th>\n",
       "      <th>name_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: So if a photon is directed through a ...</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: There’s no point, I just think it’s a...</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: One across is Aegean, eight down is N...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: I think this is the place.</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Sheldon: Leonard, I don’t think I can do this.</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&gt;&gt; Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>&gt; A corridor at a sperm bank.</td>\n",
       "      <td>Leonard: What, are you kidding? You’re a semi-...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     series                       episodes  \\\n",
       "2   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "3   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "4   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "5   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "7   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "9   >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "11  >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "13  >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "15  >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "16  >> Series 01 Episode 01 – Pilot Episode  > A corridor at a sperm bank.   \n",
       "\n",
       "                                                lines    names  name_count  \n",
       "2   Sheldon: So if a photon is directed through a ...  Sheldon         0.0  \n",
       "3                 Leonard: Agreed, what’s your point?  Leonard         0.0  \n",
       "4   Sheldon: There’s no point, I just think it’s a...  Sheldon         0.0  \n",
       "5                                 Leonard: Excuse me?  Leonard         0.0  \n",
       "7   Leonard: One across is Aegean, eight down is N...  Leonard         0.0  \n",
       "9   Leonard: Yes. Um, is this the High IQ sperm bank?  Leonard         0.0  \n",
       "11                Sheldon: I think this is the place.  Sheldon         0.0  \n",
       "13           Leonard: Thank-you. We’ll be right back.  Leonard         0.0  \n",
       "15     Sheldon: Leonard, I don’t think I can do this.  Sheldon         0.0  \n",
       "16  Leonard: What, are you kidding? You’re a semi-...  Leonard         0.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data set from names than are not \"common\"\n",
    "recurrent_names = pd.Series(name_count['names'])\n",
    "clean_scripts = all_scripts[all_scripts['names'].isin(recurrent_names)]\n",
    "\n",
    "clean_scripts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Read the ~~stats~~ scripts carefully (30 points)\n",
    "\n",
    "### Part 1: Don't put the shovel down just yet\n",
    "\n",
    "**Q3**. (2.5 points) From each dialogue line, replace punctuation marks (listed in the EXCLUDE_CHARS variable provided in `helpers/helper_functions.py`) with whitespaces, and lowercase all the text. **Do not remove any stopwords, leave them be for all the questions in this task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper function to clean the scripts and tokenize it\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0, '/helpers')\n",
    "#import helper_functions.py\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "EXCLUDE_CHARS = set(punctuation).union(set('’'))\n",
    "\n",
    "def simple_tokeniser(text):\n",
    "    return text.split()\n",
    "\n",
    "#clean_scripts = clean_scripts.reset_index()\n",
    "\n",
    "# Too long to compile\n",
    "#for i in range(len(clean_scripts)):\n",
    "#    s = str(clean_scripts['lines'][i])\n",
    "#    clean_scripts['lines'][i] = simple_tokeniser(s)\n",
    "\n",
    "clean_scripts = clean_scripts.reset_index().drop(['index'], axis=1)\n",
    "clean_scripts\n",
    "s = clean_scripts['lines']\n",
    "s = s.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the name of the character saying the line\n",
    "clean_scripts['lines'] = s\n",
    "clean_scripts.head(5)\n",
    "\n",
    "words = pd.Series(clean_scripts['lines'])\n",
    "\n",
    "for i in range(len(words)):\n",
    "    words[i] = words[i][1:]\n",
    "    \n",
    "clean_scripts['lines'] = words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. (5 points) For each term, calculate its \"corpus frequency\", i.e. its number of occurrences in the entire series. Visualize the distribution of corpus frequency using a histogram. Explain your observations. What are the appropriate x and y scales for this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count appearence of each words\n",
    "rows = []\n",
    "_ = clean_scripts.apply(lambda row: [rows.append([nn]) for nn in row.lines], axis=1)\n",
    "\n",
    "df_new = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(5)\n",
    "word_list = df_new.rename(columns={0: 'word'})\n",
    "\n",
    "word_list['word'] = word_list['word'].map(lambda x: re.sub('[^A-Za-z0-9]+', '', x))\n",
    "word_list['word'] = word_list['word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x160040f0898>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_list['count'] = 0.0\n",
    "word_count = word_list.groupby(['word']).count()\n",
    "word_count = word_count.rename(columns={'count': 'word_count'})\n",
    "\n",
    "word_count = word_count.sort_values('word_count', ascending=False)\n",
    "\n",
    "word_count.plot(kind='hist', title='Frequency of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16001d01ba8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_count.plot(kind='hist', logx=True, logy=True, title='Frequency of words (logxlogy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Most of the words are used few times. Only few words are used a lot. (xaxis: number of words usage, yavis:frequency of words with that usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Talkativity\n",
    "**Q5**. (2.5 points) For each of the recurrent characters, calculate their total number of words uttered across all episodes. Based on this, who seems to be the most talkative character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sheldon</th>\n",
       "      <td>174896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>95608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>74247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howard</th>\n",
       "      <td>64988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raj</th>\n",
       "      <td>56390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy</th>\n",
       "      <td>37381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernadette</th>\n",
       "      <td>25744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stuart</th>\n",
       "      <td>7407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Cooper</th>\n",
       "      <td>3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beverley</th>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Priya</th>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wil</th>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Wolowitz</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emily</th>\n",
       "      <td>1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arthur</th>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack</th>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leslie</th>\n",
       "      <td>1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kripke</th>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man</th>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert</th>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lines_len\n",
       "names                  \n",
       "Sheldon          174896\n",
       "Leonard           95608\n",
       "Penny             74247\n",
       "Howard            64988\n",
       "Raj               56390\n",
       "Amy               37381\n",
       "Bernadette        25744\n",
       "Stuart             7407\n",
       "Mrs Cooper         3418\n",
       "Beverley           1918\n",
       "Priya              1824\n",
       "Wil                1577\n",
       "Mrs Wolowitz       1500\n",
       "Emily              1472\n",
       "Arthur             1353\n",
       "Zack               1336\n",
       "Leslie             1164\n",
       "Kripke             1163\n",
       "Man                1162\n",
       "Bert               1065"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of word in each lines\n",
    "# here corpus is wrongly names as it was made in the question above\n",
    "corpus_scripts = clean_scripts\n",
    "corpus_scripts = corpus_scripts.drop(['name_count'], axis=1)\n",
    "corpus_scripts['lines_len'] = 0.0\n",
    "\n",
    "corpus_scripts['lines_len'] = corpus_scripts['lines'].apply(lambda row: len(row))\n",
    "\n",
    "#actual count here for nb words per person\n",
    "corpus_sum = corpus_scripts.groupby(['names']).sum()\n",
    "corpus_sum = corpus_sum.sort_values('lines_len', ascending=False)\n",
    "\n",
    "corpus_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Sheldon is the more talkative character with more than 170'000 words\n",
    "\n",
    "Bert is the character that speaks the less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. (12.5 points) For each of the recurrent characters, calculate their total number of words uttered per episode (ignoring episodes that the character does not appear in), and calculate a **robust summary statistic** for the word count distribution of each person.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**i)** (2.5 points) What changes do you observe, compared to the analysis in Q5?\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**ii)** (2.5 points) Why is this analysis an improvement over the previous one, and how could you improve it even further? _Hint: The improvement involves making your unit for word counts even more granular - you can go further down than episodes._\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**iii)** (7.5 points) Incorporate that improvement. Do you still see the same results? How **confident** can you be that the \"most talkative\" person given by this twice improved method is really more talkative than the second most talkative one? _Hint: Read the question again. A good idea would be to use bootstrapping and calculate your summary statistic on each bootstrapped set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lines_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series</th>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">&gt;&gt; Series 01 Episode 01 – Pilot Episode</th>\n",
       "      <th>Howard</th>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raj</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sheldon</th>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">&gt;&gt; Series 01 Episode 02 – The Big Bran Hypothesis</th>\n",
       "      <th>Howard</th>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raj</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sheldon</th>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">&gt;&gt; Series 01 Episode 03 – The Fuzzy Boots Corollary</th>\n",
       "      <th>Howard</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raj</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sheldon</th>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">&gt;&gt; Series 01 Episode 04 – The Luminous Fish Effect</th>\n",
       "      <th>Howard</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Cooper</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               lines_len\n",
       "series                                             names                \n",
       ">> Series 01 Episode 01 – Pilot Episode            Howard            218\n",
       "                                                   Leonard          1207\n",
       "                                                   Man                10\n",
       "                                                   Penny             554\n",
       "                                                   Raj                 8\n",
       "                                                   Sheldon          1205\n",
       ">> Series 01 Episode 02 – The Big Bran Hypothesis  Howard            242\n",
       "                                                   Leonard          1023\n",
       "                                                   Penny             582\n",
       "                                                   Raj               139\n",
       "                                                   Sheldon          1031\n",
       ">> Series 01 Episode 03 – The Fuzzy Boots Corol... Howard            321\n",
       "                                                   Leonard          1449\n",
       "                                                   Penny             319\n",
       "                                                   Raj                70\n",
       "                                                   Sheldon           722\n",
       ">> Series 01 Episode 04 – The Luminous Fish Effect Howard             51\n",
       "                                                   Leonard           451\n",
       "                                                   Mrs Cooper        781\n",
       "                                                   Penny             218"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count words per chara per episodes\n",
    "episode_word = clean_scripts.drop(['name_count'],axis=1).groupby(['series', 'names']).sum()\n",
    "\n",
    "# Now that we have the number of words said per episode per character\n",
    "episode_word.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_lines_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">lines_len</th>\n",
       "      <th>Sheldon</th>\n",
       "      <td>807.718615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leonard</th>\n",
       "      <td>456.437229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penny</th>\n",
       "      <td>354.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howard</th>\n",
       "      <td>306.753247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raj</th>\n",
       "      <td>264.800866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy</th>\n",
       "      <td>176.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernadette</th>\n",
       "      <td>123.086580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stuart</th>\n",
       "      <td>35.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Cooper</th>\n",
       "      <td>15.718615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beverley</th>\n",
       "      <td>9.004329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Priya</th>\n",
       "      <td>8.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wil</th>\n",
       "      <td>7.372294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emily</th>\n",
       "      <td>7.082251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Wolowitz</th>\n",
       "      <td>7.082251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arthur</th>\n",
       "      <td>6.419913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack</th>\n",
       "      <td>6.367965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leslie</th>\n",
       "      <td>5.541126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kripke</th>\n",
       "      <td>5.493506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man</th>\n",
       "      <td>5.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert</th>\n",
       "      <td>5.021645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean_lines_len\n",
       "          names                       \n",
       "lines_len Sheldon           807.718615\n",
       "          Leonard           456.437229\n",
       "          Penny             354.649351\n",
       "          Howard            306.753247\n",
       "          Raj               264.800866\n",
       "          Amy               176.848485\n",
       "          Bernadette        123.086580\n",
       "          Stuart             35.238095\n",
       "          Mrs Cooper         15.718615\n",
       "          Beverley            9.004329\n",
       "          Priya               8.857143\n",
       "          Wil                 7.372294\n",
       "          Emily               7.082251\n",
       "          Mrs Wolowitz        7.082251\n",
       "          Arthur              6.419913\n",
       "          Zack                6.367965\n",
       "          Leslie              5.541126\n",
       "          Kripke              5.493506\n",
       "          Man                 5.484848\n",
       "          Bert                5.021645"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets find the mean words per episode per character\n",
    "# Need to add the character with lines_len = 0 if not present in the episode?\n",
    "\n",
    "# episode_word.div(episode_word.groupby(['lines_len']).sum())\n",
    "\n",
    "episode_word_mean = episode_word.unstack().fillna(0).mean().to_frame()\n",
    "episode_word_mean = episode_word_mean.rename(columns={0: 'mean_lines_len'})\n",
    "episode_word_mean = episode_word_mean.sort_values('mean_lines_len', ascending=False)\n",
    "\n",
    "episode_word_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1663.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>363.235117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>269.752968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>487.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1633.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lines_len\n",
       "count  1663.000000\n",
       "mean    363.235117\n",
       "std     269.752968\n",
       "min       2.000000\n",
       "25%     168.000000\n",
       "50%     297.000000\n",
       "75%     487.500000\n",
       "max    1633.000000"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_word.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) (2.5 points) What changes do you observe, compared to the analysis in Q5?**\n",
    "\n",
    "It is still the same three characters that say the most words in total and per episodes (Sheldon, leonard, penny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) (2.5 points) Why is this analysis an improvement over the previous one, and how could you improve it even further? Hint: The improvement involves making your unit for word counts even more granular - you can go further down than episodes.**\n",
    "\n",
    "It is an improvement because it indicates which characters says the more per episode, and does not only have one episode where he talks a lot and is never seen again.\n",
    "\n",
    "Anther better measurement would be to see if the characters says meaningful things and not just only stop words > if the character brings new things to the story or what he says.\n",
    "\n",
    "A graph of gossips as in Task C would be great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 3: Obligatory Spark cameo\n",
    "**Q7**. (7.5 points) Write a Spark script that does the following: Given the raw input file and your list of recurrent characters, create an RDD containing (speaker, dialogue line) rows **only for the recurrent characters** (assume that you already have the list --  no need to calculate it using Spark), and then generate a vectorized bag of words representation for each dialogue line, thus generating an RDD with (speaker, bag of words vector) rows. Then, calculate an aggregated bag of words vector (sum of all vectors) for each person. The final output is therefore an RDD with each of its rows being (speaker, aggregated bag of words vector). For your bag of words vectors, you can use $1\\times|V|$ scipy CSR matrices (where $|V|$ is the size of the vocabulary). No filtering of the vocabulary is necessary for this part.\n",
    "\n",
    "You do not need to run this script, but you do need to use Spark logic and also, the syntax needs to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: The Gossip Graph (30 points)\n",
    "\n",
    "**Note: Only for this task, discard the recurrent characters whose names are not single words, e.g. Mrs. Cooper.**\n",
    "\n",
    "Let us define _gossip_ as follows: if a dialogue line of character A mentions B by name in a scene that does not involve character B, we say that “A gossips about B” in that line. Multiple mentions of the same person in a single line are counted once, but a character can gossip about several others in the same line. For the sake of simplicity, we only consider gossips where the name of the recurrent character is mentioned as it appears in our list of characters; for example, if someone says \"Cooper\" and they mean Sheldon, we discard that.\n",
    "\n",
    "**Q8**. (12.5 points) Create the two following graphs first:\n",
    "\n",
    "1. (5 points) Create the _familiarity graph_, an undirected weighted graph, in which there is a node for each recurrent character, and an edge between two characters if they appear together in at least one scene. The weight of the edge between them is the number of scenes they appear in together. If an edge exists between two people in the familiarity graph, we say that they \"know each other\".\n",
    "2. (7.5 points) Create the _gossip graph_, which is a directed weighted graph, in which there there is a node for each recurrent character, and a directed edge from the node for A to the node for B if A has gossiped about B at least once. The weight of the edge is the number of scenes in which A has gossiped about B.\n",
    "\n",
    "_Hint: You can create each graph first as an adjacency matrix and then create a networkx graph out of that._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discard names that have a space in it\n",
    "pure_scripts = clean_scripts[\" \" not in clean_scripts['names']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, answer the following questions:\n",
    "\n",
    "**Q9**. (5 points) Sheldon claims that every character in the show is familiar with everyone else through at most one intermediary. Based on the familiarity graph, is this true? If not, at most how many intermediaries are needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10**. (5 points) Who is the character through whom the largest number of these indirect familiarities happen? Calculate an appropriate centrality metric on the familiarity graph to answer this question. You can use the package networkx for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11**. (2.5 points) Another claim of Sheldon's is that every recurrent character in the show gossips about all the other recurrent characters. What property of the gossip graph would correspond to this? Does the gossip graph possess that property? If not, then is it the case that for every pair of recurrent characters, at least one gossips about the other? What property would this correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12**. (5 points) Use the gossip graph and the familiarity graph to figure out if for every pair of recurrent characters, one of them has gossiped about the other if and only if they know each other. Explain your method - the simpler, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D: The Detective's Hat (30 points)\n",
    "\n",
    "Sheldon claims that given a dialogue line, he can, with an accuracy of above 70%, say whether it's by himself or by someone else. Leonard contests this claim, since he believes that this claimed accuracy is too high. Leonard also suspects that it's easier for Sheldon to distinguish the lines that _aren't_ his, rather than those that _are_. We want you to put on the (proverbial) detective's hat and to investigate this claim.\n",
    "\n",
    "**Q13**. (7.5 points) Divide the set of all dialogue lines into two subsets: the training set, consisting of all the seasons except the last two, and the test set, consisting of the last two seasons. Each of your data points (which is one row of your matrix) is one **dialogue line**. Now, use the scikit-learn class **TfIdfVectorizer** to create TF-IDF representations for the data points in your training and test sets. Note that since you're going to train a machine learning model, everything used in the training needs to be independent of the test set. As a preprocessing step, remove stopwords and words that appear only once from your vocabulary. Use the simple tokenizer provided in `helpers/helper_functions.py` as an input to the TfidfVectorizer class, and use the words provided in `helpers/stopwords.txt` as your stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14**. (5 points) Find the set of all words in the training set that are only uttered by Sheldon. Is it possible for Sheldon to identify himself only based on these? Use the test set to assess this possibility, and explain your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15**. (17.5 points) Now, perform singular value decomposition (SVD) on the training TF-IDF matrix, and calculate a **25-dimensional approximation** for both the training and test TF-IDF matrices (you can do this using scikit-learn's **TruncatedSVD** class). Then, train a logistic regression classifier with 10-fold cross-validation (using the scikit-learn **LogisticRegressionCV** class) on the output of the SVD that given a dialogue line, tells you whether it's by Sheldon or by someone else.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**i)** (7.5 points) Report precision, recall and F1-score for both classes (Sheldon and not-Sheldon), as well as accuracy, of your classifier on the training set and the test set. You need to implement the calculation of the evaluation measures (precision, etc.) yourself -- using the scikit-learn functions for them is not allowed.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**ii)** (5 points) What difference do you observe between the model's scores on the training and test sets? What could you infer from the amount of difference you see? What about the difference between scores on the two classes? Given the performance of your classifier, is Leonard right that the accuracy Sheldon claims is unattainable? What about his suspicions about the lines that Sheldon can and cannot distinguish?\n",
    "    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**iii)** (2.5 points) List 10 of the most extreme false positives and 10 of the most extreme false negatives, in terms of the probabilities predicted by the logistic regression model. What are common features of false positives? What about the false negatives?\n",
    "    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**iv)** (2.5 points) What is the most important feature in the model? What are the 5 most important words in this feature? _Hint: Think of the definition of an SVD, and that you did an SVD on the TF-IDF matrix with dialogue lines as rows and words as columns. You have projected the original data points onto a 25-dimensional subspace -- you need to look at the unit vectors you used for the projection._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
